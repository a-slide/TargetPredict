{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Extract fasta from gff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook using Biopython and GFF to create a multi fasta file corresponding to the sequences indicated in a gff file and a reference fasta file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a gff representation and parsing class due to the unnecessary complexity of existing python parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gzip import open as gopen\n",
    "from urllib import unquote\n",
    "from collections import OrderedDict\n",
    "\n",
    "class GffFeature(object):\n",
    "    \"\"\"Object representing a gff feature\"\"\"\n",
    "    def __init__(self, seq_id, source, type, start, end, score, strand, phase, attributes):\n",
    "        self.seq_id = seq_id \n",
    "        self.source = source\n",
    "        self.type = type\n",
    "        self.start = start \n",
    "        self.end = end\n",
    "        self.score = score\n",
    "        self.strand = strand\n",
    "        self.phase = phase\n",
    "        self.attributes = attributes\n",
    "    \n",
    "    def __str__ (self):\n",
    "        \"\"\"Return a gff formated line\"\"\"\n",
    "        return \"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "            self.seq_id,\n",
    "            self.source,\n",
    "            self.type,\n",
    "            self.start, \n",
    "            self.end,\n",
    "            self.score,\n",
    "            self.strand,\n",
    "            self.phase,\n",
    "            \";\".join([\"=\".join(attribute) for attribute in self.attributes.items()]))     \n",
    "    \n",
    "class GffSequence(object):\n",
    "    \"\"\"Object representing a sequence in a gff file\"\"\"\n",
    "    \n",
    "    def __init__(self, seq_id, start, end):\n",
    "        self.seq_id = seq_id\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.features = []\n",
    "        self.features_count = 0\n",
    "    \n",
    "    def __str__ (self):\n",
    "        \"\"\"Return a gff formated line\"\"\"\n",
    "        return \"##sequence-region {} {} {}\\n{}\".format(\n",
    "            self.seq_id,\n",
    "            self.start,\n",
    "            self.end,\n",
    "            \"\\n\".join([str(feature) for feature in self.features]))\n",
    "        \n",
    "    def add_feature(self, source, type, start, end, score, strand, phase, attributes):\n",
    "        self.features.append(GffFeature(self.seq_id, source, type, start, end, score, strand, phase, attributes))\n",
    "        self.features_count += 1\n",
    "        \n",
    "class GffParser(object):\n",
    "    \"\"\"\n",
    "    A minimalistic GFF3 format parser supporting gzip decompression.\n",
    "    \"\"\"\n",
    "\n",
    "    ##### FONDAMENTAL METHODS #####\n",
    "    \n",
    "    def __init__(self, gff_file, feature_types=[]):\n",
    "        \"\"\"\n",
    "        gff_file    Path to a standard gff3 file\n",
    "        feature_types    restrict to the type of features indicated in the list (Default = all types) \n",
    "        \"\"\"\n",
    "        openFunc = gopen if gff_file.endswith(\".gz\") else open\n",
    "        self.gff_dict = OrderedDict()\n",
    "        self.gff_header = \"\"\n",
    "        self.valid_features = 0\n",
    "        self.all_features = 0\n",
    "               \n",
    "        with openFunc(gff_file) as gff:\n",
    "            for line in gff:\n",
    "                line = line.lstrip()\n",
    "                if not line: continue\n",
    "                \n",
    "                # Parse sequence delimiter in gff file (ex: ##sequence-region chr1 1 248956422)\n",
    "                if line.startswith(\"##sequence-region\"):\n",
    "\n",
    "                    # Part and verify that the number of fields is standard\n",
    "                    parts = line.strip().split()\n",
    "                    assert len(parts) == 4, \"File format is not standard-compatible: Invalid sequence-region pragma\"\n",
    "\n",
    "                    # Create a GffSequence\n",
    "                    seq_id = unquote(parts[1])\n",
    "                    self.gff_dict[seq_id]= GffSequence (seq_id = seq_id, start = int(parts[2]), end = int(parts[3]))\n",
    "\n",
    "                # Parse the general gff header\n",
    "                elif line.startswith(\"#\"):\n",
    "                    self.gff_header+=line\n",
    "\n",
    "                # Parse gff features\n",
    "                else:\n",
    "\n",
    "                    # Count all features\n",
    "                    self.all_features += 1\n",
    "                    if self.all_features % 1000 == 0:\n",
    "                        print (\"  {} features parsed\".format(all_features))\n",
    "\n",
    "                    # Part and verify that the number of fields is standard\n",
    "                    parts = line.strip().split(\"\\t\")\n",
    "                    assert len(parts) == 9, \"File format is not standard-compatible : Invalid feature description line\"\n",
    "\n",
    "                    # Verify first if the feature type is allowed\n",
    "                    type = '.' if parts[2] == \".\" else unquote(parts[2])\n",
    "                    if not feature_types or type in feature_types:\n",
    "\n",
    "                        # Count valid features\n",
    "                        self.valid_features += 1\n",
    "\n",
    "                        # Extract the sequence id and verify that the corresponding sequence-region pragma is already in the dict\n",
    "                        seq_id = '.' if parts[0] == \".\" else unquote(parts[0])\n",
    "                        assert seq_id != \".\", \"File format is not standard-compatible : Missing seq_id of a feature\"\n",
    "                        assert seq_id in self.gff_dict, \"File format is not standard-compatible : Missing or misplaced sequence-region pragma\"\n",
    "\n",
    "                        # Finally add the feature to the feature list corresponding to the seqid entry in gff_dict\n",
    "                        self.gff_dict[seq_id].add_feature(\n",
    "                            source = '.' if parts[1] == \".\" else unquote(parts[1]),\n",
    "                            type = type,\n",
    "                            start = '.' if parts[3] == '.' else int(parts[3]),\n",
    "                            end = '.' if parts[4] == '.' else int(parts[4]),\n",
    "                            score = '.' if parts[5] == '.' else float(parts[4]),\n",
    "                            strand = '.' if parts[6] == '.' else unquote(parts[6]),\n",
    "                            phase = '.' if parts[7] == '.' else int(parts[7]),\n",
    "                            attributes = self._parse_attributes(parts[8]))\n",
    "    \n",
    "    def __str__ (self):\n",
    "        \"\"\"Return a gff formated line\"\"\"\n",
    "        \n",
    "        return \"{}{}\".format(\n",
    "            self.gff_header,\n",
    "            \"\\n\".join([str(sequence) for sequence in self.gff_dict.values()]))\n",
    "    \n",
    "    ##### PRIVATE METHODS #####\n",
    "                                 \n",
    "    def _parse_attributes(self, attribute_string):\n",
    "        \"\"\"Parse the GFF3 attribute column and return a dict\"\"\"\n",
    "        \n",
    "        # Empty dict to collect features attributes\n",
    "        attributes_dict = OrderedDict()\n",
    "        \n",
    "        # Parse and return a dict of all attributes if attribute_string is defined    \n",
    "        if attribute_string != \".\":\n",
    "            for attribute in attribute_string.split(\";\"):\n",
    "                key, value = attribute.split(\"=\")\n",
    "                attributes_dict[unquote(key)] = unquote(value)\n",
    "        return attributes_dict\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test GffFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\tHAVANA\tgene\t11869\t14409\t.\t+\t.\tID=ENSG00000223972.5;gene_id=ENSG00000223972.5;gene_type=transcribed_unprocessed_pseudogene;gene_status=KNOWN;gene_name=DDX11L1;level=2;havana_gene=OTTHUMG00000000961.2\n",
      "chr1\tHAVANA\tgene\t11869\t14409\t.\t+\t.\tID=ENSG00000223972.5;gene_id=ENSG00000223972.5;gene_type=transcribed_unprocessed_pseudogene;gene_status=KNOWN;gene_name=DDX11L1;level=2;havana_gene=OTTHUMG00000000961.2\n"
     ]
    }
   ],
   "source": [
    "gff_line = \"chr1\tHAVANA\tgene\t11869\t14409\t.\t+\t.\tID=ENSG00000223972.5;gene_id=ENSG00000223972.5;gene_type=transcribed_unprocessed_pseudogene;gene_status=KNOWN;gene_name=DDX11L1;level=2;havana_gene=OTTHUMG00000000961.2\"\n",
    "parts = gff_line.strip().split(\"\\t\")\n",
    "\n",
    "attributes_dict = OrderedDict()\n",
    "for attribute in parts[8].split(\";\"):\n",
    "    key, value = attribute.split(\"=\")\n",
    "    attributes_dict[unquote(key)] = unquote(value)\n",
    "\n",
    "gff_feature = GffFeature (parts[0], parts[1], parts[2], parts[3], parts[4], parts[5], parts[6], parts[7], attributes_dict)\n",
    "\n",
    "print (gff_line)\n",
    "print (gff_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test GffParser by parsing and rewriting the gff file afterward. OK with a simple file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##gff-version 3\n",
      "#description: -\n",
      "#provider: adrien leger\n",
      "#contact: adrien.leger <at> gmail <dot> com\n",
      "#format: gff3\n",
      "#date: 2015-08-03\n",
      "##sequence-region chr1 1 1000\n",
      "chr1\tHAVANA\texon\t200\t300\t.\t+\t.\tID=exon:ENST00000456328.2:1;Parent=ENST00000456328.2;gene_id=ENSG00000223972.5;transcript_id=ENST00000456328.2;gene_type=transcribed_unprocessed_pseudogene;gene_status=KNOWN;gene_name=DDX11L1;transcript_type=processed_transcript;transcript_status=KNOWN;transcript_name=DDX11L1-002;exon_number=1;exon_id=ENSE00002234944.1;level=2;transcript_support_level=1;havana_gene=OTTHUMG00000000961.2;havana_transcript=OTTHUMT00000362751.1;tag=basic\n",
      "chr1\tHAVANA\texon\t600\t700\t.\t+\t.\tID=exon:ENST00000456328.2:2;Parent=ENST00000456328.2;gene_id=ENSG00000223972.5;transcript_id=ENST00000456328.2;gene_type=transcribed_unprocessed_pseudogene;gene_status=KNOWN;gene_name=DDX11L1;transcript_type=processed_transcript;transcript_status=KNOWN;transcript_name=DDX11L1-002;exon_number=2;exon_id=ENSE00003582793.1;level=2;transcript_support_level=1;havana_gene=OTTHUMG00000000961.2;havana_transcript=OTTHUMT00000362751.1;tag=basic\n",
      "##sequence-region chr2 1 1000\n",
      "chr2\tHAVANA\texon\t800\t900\t.\t-\t.\tID=exon:ENST00000460464.1:1;Parent=ENST00000460464.1;gene_id=ENSG00000184731.5;transcript_id=ENST00000460464.1;gene_type=protein_coding;gene_status=KNOWN;gene_name=FAM110C;transcript_type=processed_transcript;transcript_status=KNOWN;transcript_name=FAM110C-003;exon_number=1;exon_id=ENSE00001832279.1;level=2;transcript_support_level=3;havana_gene=OTTHUMG00000151321.1;havana_transcript=OTTHUMT00000322222.1\n",
      "chr2\tHAVANA\texon\t300\t400\t.\t-\t.\tID=exon:ENST00000460464.1:2;Parent=ENST00000460464.1;gene_id=ENSG00000184731.5;transcript_id=ENST00000460464.1;gene_type=protein_coding;gene_status=KNOWN;gene_name=FAM110C;transcript_type=processed_transcript;transcript_status=KNOWN;transcript_name=FAM110C-003;exon_number=2;exon_id=ENSE00001955915.1;level=2;transcript_support_level=3;havana_gene=OTTHUMG00000151321.1;havana_transcript=OTTHUMT00000322222.1\n",
      "##sequence-region chr3 1 1000\n",
      "chr3\tHAVANA\texon\t100\t200\t.\t+\t.\tID=exon:ENST00000256509.6:1;Parent=ENST00000256509.6;gene_id=ENSG00000134121.9;transcript_id=ENST00000256509.6;gene_type=protein_coding;gene_status=KNOWN;gene_name=CHL1;transcript_type=protein_coding;transcript_status=KNOWN;transcript_name=CHL1-001;exon_number=1;exon_id=ENSE00001939343.1;level=2;protein_id=ENSP00000256509.2;transcript_support_level=1;ccdsid=CCDS2556.1;havana_gene=OTTHUMG00000090601.10;havana_transcript=OTTHUMT00000207155.3;tag=basic,appris_principal_1,CCDS\n",
      "chr3\tHAVANA\texon\t700\t800\t.\t+\t.\tID=exon:ENST00000256509.6:2;Parent=ENST00000256509.6;gene_id=ENSG00000134121.9;transcript_id=ENST00000256509.6;gene_type=protein_coding;gene_status=KNOWN;gene_name=CHL1;transcript_type=protein_coding;transcript_status=KNOWN;transcript_name=CHL1-001;exon_number=2;exon_id=ENSE00001829282.1;level=2;protein_id=ENSP00000256509.2;transcript_support_level=1;ccdsid=CCDS2556.1;havana_gene=OTTHUMG00000090601.10;havana_transcript=OTTHUMT00000207155.3;tag=basic,appris_principal_1,CCDS\n"
     ]
    }
   ],
   "source": [
    "gff = GffParser (gff_file=\"./test/sample.gff\")\n",
    "print (gff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "class GffFastaExtractor (object):\n",
    "    \n",
    "    ##### FONDAMENTAL METHODS #####\n",
    "    \n",
    "    def __init__ (self, seq, gff, out_name=\"out\", feature_types=[]):\n",
    "        \"\"\"Init fonction parsing fasta and gff files\"\"\"\n",
    "        \n",
    "        print(\"Initialize GffFastaExtractor\")\n",
    "        \n",
    "        self.seq = seq\n",
    "        self.gff = gff\n",
    "        self.out_name = out_name\n",
    "        self.feature_type = feature_types\n",
    "        \n",
    "        # Parse the fasta sequence and store in a dict\n",
    "        print(\"  Parsing fasta file\")\n",
    "        with open (self.seq, \"r\") as seq_in:\n",
    "            self.seq_dict = SeqIO.to_dict(SeqIO.parse(seq_in, \"fasta\"))\n",
    "        \n",
    "        # Parse the gff file with GffParser\n",
    "        print(\"  Parsing gff file\")\n",
    "        self.gff_parser = GffParser (gff_file=gff, feature_types=self.feature_type)\n",
    "\n",
    "    ##### PUBLIC METHODS #####\n",
    "            \n",
    "    def __call__ (self, offset=0):\n",
    "        \"\"\"Launch the extraction of features \"\"\"\n",
    "               \n",
    "        # Parse the gff parser and the sequence dictionary to extract the sequence of the features\n",
    "        print(\"Extract features and write fasta output\")\n",
    "        with open (self.out_name, \"w\") as seq_out:\n",
    "            for seq_id, gff_sequence in self.gff_parser.gff_dict.items():\n",
    "                \n",
    "                assert seq_id in self.seq_dict, \"fasta and gff are incompatible: {} not found in fasta\".format(seq_id)\n",
    "                \n",
    "                print (\"  Extracting features from sequence {}\".format(seq_id))\n",
    "                for feature in gff_sequence.features:\n",
    "                    gff_line = str (feature)\n",
    "                    seq_line = self.extract_seq(key, sub_feature, offset)\n",
    "                    seq_out.write(\">{}\\n{}\\n\".format(gff_line, seq_line))\n",
    "                \n",
    "        print (\"Done\")\n",
    "        \n",
    "        \n",
    "    ##### PRIVATE METHODS #####\n",
    "            \n",
    "    def extract_seq(self, key, feature, offset=0):\n",
    "        \n",
    "        # Extract start and stop of the feature\n",
    "        if not offset:\n",
    "            start = feature.location.start+1\n",
    "            end = feature.location.end\n",
    "            \n",
    "        # Extract and correct if outside of boundaries\n",
    "        else:\n",
    "            start = feature.location.start-offset+1\n",
    "            if start<0:\n",
    "                start=0\n",
    "            end = feature.location.end+offset\n",
    "            if end>len(self.seq_dict[key]):\n",
    "                end=len(self.seq_dict[key])\n",
    "        \n",
    "        if feature.location.strand == 1:\n",
    "            return str(self.seq_dict[key][start:end].seq)\n",
    "        \n",
    "        elif feature.location.strand == -1:\n",
    "            return str(self.seq_dict[key][start:end].reverse_complement().seq)\n",
    "        \n",
    "        else:\n",
    "            print feature\n",
    "            print feature.location.strand\n",
    "            raise Exception\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test without offset restricted to exons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize GffFastaExtractor\n",
      "  Parsing fasta file\n",
      "  Parsing gff file\n",
      "Extract features and write fasta output\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "E = GffFastaExtractor(seq=\"./test/sample.fa\", gff=\"./test/sample.gff\", out_name=\"./test/test_exons_no_offset.fa\")\n",
    "E()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with 50 pb offset restricted to exons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize GffFastaExtractor\n",
      "  Parsing fasta file\n",
      "  Parsing gff file\n",
      "Extract features and write fasta output\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "E = GffFastaExtractor(seq=\"./test/sample.fa\", gff=\"./test/sample.gff\", out_name=\"./test/test_exons_50pb_offset.fa\")\n",
    "E(offset=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene_status=KNOWN\n",
      "havana_gene=OTTHUMG00000000961.2\n",
      "level=2\n",
      "gene_id=ENSG00000223972.5\n",
      "gene_type=transcribed_unprocessed_pseudogene\n",
      "ID=ENSG00000223972.5\n",
      "gene_name=DDX11L1\n"
     ]
    }
   ],
   "source": [
    "string = \"ID=ENSG00000223972.5;gene_id=ENSG00000223972.5;gene_type=transcribed_unprocessed_pseudogene;gene_status=KNOWN;gene_name=DDX11L1;level=2;havana_gene=OTTHUMG00000000961.2\"\n",
    "\n",
    "b= {a.split(\"=\")[0]: a.split(\"=\")[1] for a in string.split(\";\")}\n",
    "\n",
    "print \"\\n\".join([\"=\".join(sl) for sl in b.items()])\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
