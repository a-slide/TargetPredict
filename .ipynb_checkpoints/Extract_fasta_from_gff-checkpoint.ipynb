{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Extract fasta from gff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook using Biopython and GFF to create a multi fasta file corresponding to the sequences indicated in a gff file and a reference fasta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from BCBio import GFF\n",
    "from Bio import SeqIO\n",
    "\n",
    "class GffFastaExtractor (object):\n",
    "    \n",
    "    ##### FONDAMENTAL METHODS #####\n",
    "    \n",
    "    def __init__ (self, seq, gff, out_name=\"out\"):\n",
    "        \"\"\"Init fonction parsing fasta and gff files\"\"\"\n",
    "        \n",
    "        print(\"Initialize GffFastaExtractor\")\n",
    "        \n",
    "        self.seq = seq\n",
    "        self.gff = gff\n",
    "        self.out_name = out_name\n",
    "        \n",
    "        # Parse the fasta sequence and store in a dict\n",
    "        print(\"  Parsing fasta file\")\n",
    "        with open (self.seq, \"r\") as seq_in:\n",
    "            self.seq_dict = SeqIO.to_dict(SeqIO.parse(seq_in, \"fasta\"))\n",
    "        \n",
    "        # Parse the gff sequence and store in a dict\n",
    "        print(\"  Parsing gff file\")\n",
    "        with open (self.gff, \"r\") as gff_in:\n",
    "            self.gff_dict = {i.id:i for i in GFF.parse(gff_in)}\n",
    "\n",
    "    ##### PUBLIC METHODS #####\n",
    "            \n",
    "    def __call__ (self, offset=0, feature_type=None):\n",
    "        \"\"\"Launch the extraction of features \"\"\"\n",
    "        \n",
    "        print(\"Extract features and write fasta output\")\n",
    "        # Parse the gff and sequence dictionary to extract the sequence of the features\n",
    "        \n",
    "        with open (self.out_name, \"w\") as seq_out:\n",
    "        \n",
    "            for key in sorted(self.seq_dict.keys()):\n",
    "                print (\"  Sequence {}\".format(key))\n",
    "             \n",
    "                if self.gff_dict[key].features:\n",
    "                    for feature in self.gff_dict[key].features:\n",
    "                        if not feature_type or feature.type == feature_type:\n",
    "                            gff_line = self.extract_gff(key, feature)\n",
    "                            seq_line = self.extract_seq(key, feature, offset)\n",
    "                            seq_out.write(\">{}\\n{}\\n\".format(gff_line, seq_line))\n",
    "\n",
    "                        if feature.sub_features:\n",
    "                            for sub_feature in feature.sub_features:\n",
    "                                if not feature_type or sub_feature.type == feature_type:\n",
    "                                    gff_line = self.extract_gff(key, sub_feature)\n",
    "                                    seq_line = self.extract_seq(key, sub_feature, offset)\n",
    "                                    seq_out.write(\">{}\\n{}\\n\".format(gff_line, seq_line))\n",
    "        print (\"Done\")\n",
    "        \n",
    "        \n",
    "    ##### PRIVATE METHODS #####\n",
    "    \n",
    "    def extract_gff(self, key, feature):\n",
    "        # Extract the optional fields from section which is a little messy\n",
    "        qualifier_str=\"\"\n",
    "        for qualifier in [\"ID\",\"ID=exon\",\"Parent\",\"gene_id\",\"transcript_id\",\"gene_type\",\"gene_status\",\"gene_name\",\"transcript_type\",\n",
    "             \"transcript_status\", \"transcript_name\",\"exon_number\",\"exon_id\",\"level\", \"protein_id\",\"transcript_support_level\",\n",
    "             \"ccdsid\",\"havana_gene\", \"havana_transcript\", \"tag\"]:\n",
    "            if qualifier in feature.qualifiers:\n",
    "                \n",
    "                if type(feature.qualifiers[qualifier])==list:\n",
    "                    qualifier_str+= \"{}={};\".format(qualifier, \",\".join(feature.qualifiers[qualifier]))\n",
    "                else:\n",
    "                    qualifier_str+= \"{}={};\".format(qualifier, feature.qualifiers[qualifier])\n",
    "        \n",
    "        # Extract the main fields from the other sections         \n",
    "        try:\n",
    "            return(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "                key,\n",
    "                feature.qualifiers[\"source\"][0] if feature.qualifiers[\"source\"] else \"UNKNOWN\",\n",
    "                feature.type,\n",
    "                feature.location.start+1,\n",
    "                feature.location.end,\n",
    "                \".\",\n",
    "                \"+\" if feature.location.strand == 1 else \"-\",\n",
    "                \".\",\n",
    "                qualifier_str[:-1] ))\n",
    "        \n",
    "        except KeyError as E:\n",
    "            print E\n",
    "            print feature.qualifiers\n",
    "            return [\"ERROR\"]\n",
    "    \n",
    "    def extract_seq(self, key, feature, offset=0):\n",
    "        \n",
    "        # Extract start and stop of the feature\n",
    "        if not offset:\n",
    "            start = feature.location.start+1\n",
    "            end = feature.location.end\n",
    "            \n",
    "        # Extract and correct if outside of boundaries\n",
    "        else:\n",
    "            start = feature.location.start-offset+1\n",
    "            if start<0:\n",
    "                start=0\n",
    "            end = feature.location.end+offset\n",
    "            if end>len(self.seq_dict[key]):\n",
    "                end=len(self.seq_dict[key])\n",
    "        \n",
    "        if feature.location.strand == 1:\n",
    "            return str(self.seq_dict[key][start:end].seq)\n",
    "        \n",
    "        elif feature.location.strand == -1:\n",
    "            return str(self.seq_dict[key][start:end].reverse_complement().seq)\n",
    "        \n",
    "        else:\n",
    "            print feature\n",
    "            print feature.location.strand\n",
    "            raise Exception\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test without offset restricted to exons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize GffFastaExtractor\n",
      "  Parsing fasta file\n",
      "  Parsing gff file\n",
      "Extract features and write fasta output\n",
      "  Sequence chr1\n",
      "  Sequence chr2\n",
      "  Sequence chr3\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "E = GffFastaExtractor(seq=\"./test/sample.fa\", gff=\"./test/sample.gff\", out_name=\"./test/test_exons_no_offset.fa\")\n",
    "E(feature_type=\"exon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with 50 pb offset restricted to exons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize GffFastaExtractor\n",
      "  Parsing fasta file\n",
      "  Parsing gff file\n",
      "Extract features and write fasta output\n",
      "  Sequence chr1\n",
      "  Sequence chr2\n",
      "  Sequence chr3\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "E = GffFastaExtractor(seq=\"./test/sample.fa\", gff=\"./test/sample.gff\", out_name=\"./test/test_exons_50pb_offset.fa\")\n",
    "E(feature_type=\"exon\", offset=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
